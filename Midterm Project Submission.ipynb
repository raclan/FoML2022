{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ryanr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import contractions\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import nltk\n",
    "from nltk.translate import meteor, meteor_score\n",
    "nltk.download('wordnet')\n",
    "import Levenshtein\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open and convert data into dataframes\n",
    "training = open('train_with_label.txt', encoding='utf-8').read().split('\\n')[:4077]\n",
    "\n",
    "temp = []\n",
    "for row in training:\n",
    "    temp.append(row.split('\\t'))\n",
    "\n",
    "traindf = pd.DataFrame(temp)\n",
    "\n",
    "dev = open('dev_with_label.txt', encoding='utf-8').read().split('\\n')\n",
    "\n",
    "temp = []\n",
    "for row in dev:\n",
    "    temp.append(row.split('\\t'))\n",
    "\n",
    "devdf = pd.DataFrame(temp)[:-1]\n",
    "\n",
    "#Create string arrays for each dataset\n",
    "train_col1 = traindf.iloc[:,1]\n",
    "train_col2 = traindf.iloc[:,2]\n",
    "\n",
    "dev_col1 = devdf.iloc[:,1]\n",
    "dev_col2 = devdf.iloc[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the strings to remove punctation, remove common words, and lowercase\n",
    "def clean_string(text):\n",
    "    text = text.replace('â€™', '\\'')\n",
    "    text = contractions.fix(text)\n",
    "    text = ''.join([word for word in text if word not in string.punctuation])\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "#Define new features\n",
    "def new_features(col1, col2):\n",
    "\n",
    "    #Find Euclidean Distance\n",
    "    edist = []\n",
    "\n",
    "    #Find cosine similarity\n",
    "    csim = []\n",
    "\n",
    "    #Find lengths of sentences (words)\n",
    "    length1 = []\n",
    "    length2 = []\n",
    "\n",
    "    #Find slices of sentences (number of similar words between sentences)\n",
    "    slices = []\n",
    "\n",
    "    #Find meteor scores\n",
    "    mscores = []\n",
    "\n",
    "    #Find Levenshtein distance\n",
    "    ldists = []\n",
    "\n",
    "    #Find BLEU scores\n",
    "    bscore1s = []\n",
    "    bscore2s = []\n",
    "    bscore3s = []\n",
    "    bscore4s = []\n",
    "\n",
    "    #Find Levenshtein ratio\n",
    "    lratios = []\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    for (sent1, sent2) in zip(col1, col2):\n",
    "\n",
    "        #Euclidean Distances\n",
    "        corpus = [sent1, sent2]\n",
    "        features = vectorizer.fit_transform(corpus).todense() \n",
    "        edist.append(euclidean_distances(features[0], features[1])[0][0])\n",
    "\n",
    "        #Cosine Similarities\n",
    "        vectors = vectorizer.fit_transform(corpus).toarray()\n",
    "        csim.append(cosine_similarity(vectors)[0][1])\n",
    "\n",
    "        #Lengths of sentences (words)\n",
    "        length1.append(len(sent1.split()))\n",
    "        length2.append(len(sent2.split()))\n",
    "\n",
    "        #Slices\n",
    "        slice = 0  \n",
    "        for word1 in sent1.split():\n",
    "            for word2 in sent2.split():\n",
    "                if word1 == word2:\n",
    "                    slice += 1\n",
    "        slices.append(slice)\n",
    "  \n",
    "        #Meteor Scores\n",
    "        mscore = meteor_score.meteor_score([sent1], sent2)\n",
    "        mscores.append(mscore)\n",
    "\n",
    "        #Levenshtein Distances\n",
    "        ldist = Levenshtein.distance(sent1, sent2)\n",
    "        ldists.append(ldist)\n",
    "\n",
    "        #Levenshtein Ratios\n",
    "        lratio = Levenshtein.ratio(sent1, sent2)\n",
    "        lratios.append(lratio)\n",
    "\n",
    "        #BLEU Scores\n",
    "        bscore1 = sentence_bleu([sent1.split()], sent2.split(), weights=[1])\n",
    "        bscore1s.append(bscore1)\n",
    "\n",
    "        bscore2 = sentence_bleu([sent1.split()], sent2.split(), weights=[1/2, 1/2])\n",
    "        bscore2s.append(bscore2)\n",
    "\n",
    "        bscore3 = sentence_bleu([sent1.split()], sent2.split(), weights=[1/3, 1/3, 1/3])\n",
    "        bscore3s.append(bscore3)\n",
    "\n",
    "        bscore4 = sentence_bleu([sent1.split()], sent2.split(), weights=[1/4, 1/4, 1/4, 1/4])\n",
    "        bscore4s.append(bscore4)\n",
    "\n",
    "    #Find absolute value of difference between lengths\n",
    "    lengthdiff = abs(np.array(length2) - np.array(length1))\n",
    "\n",
    "    bscores = min(1, len(sent2.split())/len(sent1.split())) * (np.array(bscore1s)*np.array(bscore2s)*np.array(bscore3s)*np.array(bscore4s))**(1/4)\n",
    "\n",
    "    return edist, csim, length1, length2, lengthdiff, slices, mscores, ldists, lratios, bscores\n",
    "\n",
    "#Create df with new features given two string arrays\n",
    "def new_df(col1, col2):\n",
    "    edist, csim, length1, length2, lengthdiff, slices, mscores, ldists, lratios, bscores = new_features(col1, col2) \n",
    "\n",
    "    return_df = pd.DataFrame()\n",
    "    return_df['edist'] = edist\n",
    "    return_df['csim'] = csim\n",
    "    return_df['length1'] = length1\n",
    "    return_df['length2'] = length2\n",
    "    return_df['lengthdiff'] = lengthdiff\n",
    "    return_df['slices'] = slices\n",
    "    return_df['mscores'] = mscores\n",
    "    return_df['ldists'] = ldists\n",
    "    return_df['lratios'] = lratios\n",
    "    return_df['bscores'] = bscores\n",
    "\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training and dev sets with cleaning\n",
    "train1 = list(map(clean_string, train_col1))\n",
    "train2 = list(map(clean_string, train_col2))\n",
    "\n",
    "dev1 = list(map(clean_string, dev_col1))\n",
    "dev2 = list(map(clean_string, dev_col2))\n",
    "\n",
    "cleantrain = new_df(train1, train2)\n",
    "cleantrain['paraphrase'] = traindf[3]\n",
    "\n",
    "cleandev = new_df(dev1, dev2)\n",
    "cleandev['paraphrase'] = devdf[3]\n",
    "\n",
    "X_train = cleantrain.drop('paraphrase', axis=1)\n",
    "y_train = cleantrain['paraphrase']\n",
    "X_dev = cleandev.drop('paraphrase', axis=1)\n",
    "y_dev = cleandev['paraphrase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel='poly', random_state=9, gamma=0.1, C=10, class_weight='balanced')\n",
    "pipeline = make_pipeline(StandardScaler(with_mean=False), model)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_dev)\n",
    "\n",
    "print(\"Accuracy: {}\\n\".format(accuracy_score(y_dev,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51060068504f0ac08f07c76779ded23f779c75b6ec98a50a3896701dbf655d52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
